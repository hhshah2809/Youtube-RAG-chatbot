
# ğŸ¥ YouTube RAG Chatbot (Streamlit + LangChain + FAISS)

A **Retrieval-Augmented Generation (RAG) chatbot** that lets you **chat with any YouTube video** using its transcript.
The chatbot retrieves relevant transcript chunks using **FAISS vector search** and answers questions using an **LLM**, with **chat history support (GPT-style UI)**.

---

## ğŸš€ Features

* ğŸ”— Paste any **YouTube video URL**
* ğŸ“ Automatically fetches **video transcript**
* ğŸ“š Builds **FAISS vector store** from transcript
* ğŸ” Semantic search using **HuggingFace embeddings**
* ğŸ¤– Answers using **LLM (Gemini / HuggingFace models)**
* ğŸ’¬ **GPT-style chat interface**
* ğŸ§  Maintains **chat history**
* â• Dynamically adds **user queries to FAISS**
* ğŸ’¯ Fully local + free-tier friendly

---

## ğŸ§  Architecture (High Level)

```
YouTube URL
   â†“
Transcript Extraction
   â†“
Text Chunking
   â†“
Embeddings (MiniLM)
   â†“
FAISS Vector Store
   â†“
Retriever
   â†“
Prompt + Chat History
   â†“
LLM
   â†“
Answer
```

---

## ğŸ› ï¸ Tech Stack

| Component  | Tool                                   |
| ---------- | -------------------------------------- |
| UI         | Streamlit                              |
| LLM        | HuggingFace / Gemini                   |
| Embeddings | sentence-transformers/all-MiniLM-L6-v2 |
| Vector DB  | FAISS                                  |
| RAG        | LangChain                              |
| Transcript | youtube-transcript-api                 |

---

## ğŸ“¦ Installation

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/your-username/youtube-rag-chatbot.git
cd youtube-rag-chatbot
```

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
venv\Scripts\activate   # Windows
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ”‘ Environment Variables

Create a `.env` file (only required if using Gemini):

```env
GOOGLE_API_KEY=your_google_api_key
```

> ğŸ’¡ Not required if you use HuggingFace models.

---

## â–¶ï¸ Run the App

```bash
streamlit run youtuberag.py
```

Open browser at:

```
http://localhost:8501
```

---

## ğŸ§ª How It Works (Step-by-Step)

1. User enters **YouTube URL**
2. Transcript is fetched via `youtube-transcript-api`
3. Transcript is split into overlapping chunks
4. Chunks are embedded using **MiniLM**
5. FAISS stores embeddings
6. User asks a question
7. Relevant chunks are retrieved
8. Prompt + chat history are sent to LLM
9. LLM generates answer
10. Conversation history is updated

---

## ğŸ’¬ Chat History Handling

* Stored in `st.session_state["messages"]`
* Last **2 messages** injected into prompt
* Enables **follow-up questions**
* GPT-like conversational flow

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ youtuberag.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ .env
â””â”€â”€ venv/
```

---

## âš ï¸ Limitations

* Depends on transcript availability
* Free LLM APIs have rate limits
* Long videos may take time to embed

---

## ğŸ”® Future Improvements

* ğŸ¯ Source citations per answer
* ğŸ—‚ï¸ Multiple video support
* ğŸ’¾ Persistent FAISS storage
* ğŸ§‘â€ğŸ’¼ User authentication
* ğŸŒ Deployment on cloud

---

## ğŸ§  Learning Outcomes

* RAG fundamentals
* FAISS vector search
* LLM prompt engineering
* Chat history management
* Streamlit state handling

---

## ğŸ‘¨â€ğŸ’» Author

**Het Shah**
Built as a hands-on project to deeply understand **RAG + LLMs + Vector Databases**

---

## â­ If this helped you

Give the repo a â­ and feel free to fork & extend!

